{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://gitlab.com/ibm/skills-network/courses/placeholder101/-/raw/master/labs/module%201/images/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extract Transform Load (ETL) Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "-   Read CSV and JSON file types.\n",
    "-   Extract data from the above file types.\n",
    "-   Transform data.\n",
    "-   Save the transformed data in a ready-to-load format which data engineers can use to load into an RDBMS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob                         # this module helps in selecting files \n",
    "import pandas as pd                 # this module helps in processing CSV files\n",
    "from pandas import DataFrame as pddf     # importing Pandas DataFrame attribute separately to try fix an error\n",
    "import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-07-03 15:58:36--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2707 (2.6K) [application/zip]\n",
      "Saving to: 'source.zip'\n",
      "\n",
      "     0K ..                                                    100%  416M=0s\n",
      "\n",
      "2021-07-03 15:58:37 (416 MB/s) - 'source.zip' saved [2707/2707]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  source.zip\n",
      "  inflating: source3.json            \n",
      "  inflating: source1.csv             \n",
      "  inflating: source2.csv             \n",
      "  inflating: source3.csv             \n",
      "  inflating: source1.json            \n",
      "  inflating: source2.json            \n",
      "  inflating: source1.xml             \n",
      "  inflating: source2.xml             \n",
      "  inflating: source3.xml             \n"
     ]
    }
   ],
   "source": [
    "!unzip source.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile    = \"temp.tmp\"               # file used to store all extracted data\n",
    "logfile    = \"logfile.txt\"            # all event logs will be stored in this file\n",
    "targetfile = \"transformed_data.csv\"   # file where transformed data is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_from_csv(file_to_process):\n",
    "#     dataframe = pd.read_csv(file_to_process)\n",
    "#     return dataframe\n",
    "\n",
    "def csvExtract(csvFile):\n",
    "    dframe = pd.read_csv(csvFile)\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_from_json(file_to_process):\n",
    "#     dataframe = pd.read_json(file_to_process,lines=True)\n",
    "#     return dataframe\n",
    "\n",
    "def jsonExtract(jsonFile):\n",
    "    dframe = pd.read_json(jsonFile,lines=True)\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_from_xml(file_to_process):\n",
    "#     dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n",
    "#     tree = ET.parse(file_to_process)\n",
    "#     root = tree.getroot()\n",
    "#     for person in root:\n",
    "#         name = person.find(\"name\").text\n",
    "#         height = float(person.find(\"height\").text)\n",
    "#         weight = float(person.find(\"weight\").text)\n",
    "#         dataframe = dataframe.append({\"name\":name, \"height\":height, \"weight\":weight}, ignore_index=True)\n",
    "#     return dataframe\n",
    "\n",
    "def xmlExtract(xmlFile):\n",
    "    dframe = pddf(columns=[\"name\", \"height\", \"weight\"])\n",
    "    tree = ET.parse(xmlFile)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        name = person.find(\"name\").text\n",
    "        height = float(person.find(\"height\").text)\n",
    "        weight = float(person.find(\"weight\").text)\n",
    "        dframe = dframe.append({\"name\":name, \"height\":height, \"weight\":weight}, ignore_index=True)\n",
    "    return dframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  def extract():\n",
    "#    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data\n",
    "#     \n",
    "#     #process all csv files\n",
    "#     for csvfile in glob.glob(\"*.csv\"):\n",
    "#         extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
    "#         \n",
    "#     #process all json files\n",
    "#     for jsonfile in glob.glob(\"*.json\"):\n",
    "#         extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
    "#     \n",
    "#     #process all xml files\n",
    "#     for xmlfile in glob.glob(\"*.xml\"):\n",
    "#         extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
    "#         \n",
    "#     return extracted_data\n",
    "\n",
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # This creates the empty dataframe to append to\n",
    "    \n",
    "    # First, process all CSV files via loop\n",
    "    for csvFile in glob.glob(\"*.csv\"):\n",
    "        extracted_data = extracted_data.append(csvExtract(csvFile), ignore_index=True)\n",
    "        \n",
    "    # Second, process all json files\n",
    "    for jsonFile in glob.glob(\"*.json\"):\n",
    "        extracted_data = extracted_data.append(jsonExtract(jsonFile), ignore_index=True)\n",
    "        \n",
    "    # Lastly, process all xml files\n",
    "    for xmlFile in glob.glob(\"*.xml\"):\n",
    "        extracted_data = extracted_data.append(xmlExtract(xmlFile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform function does the following tasks.\n",
    "\n",
    "1.  Convert height which is in inches to millimeter\n",
    "2.  Convert weight which is in pounds to kilograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform(data):\n",
    "#         #Convert height which is in inches to millimeter\n",
    "#         #Convert the datatype of the column into float\n",
    "#         #data.height = data.height.astype(float)\n",
    "#         #Convert inches to meters and round off to two decimals(one inch is 0.0254 meters)\n",
    "#         data['height'] = round(data.height * 0.0254,2)\n",
    "#         \n",
    "#         #Convert weight which is in pounds to kilograms\n",
    "#         #Convert the datatype of the column into float\n",
    "#         #data.weight = data.weight.astype(float)\n",
    "#         #Convert pounds to kilograms and round off to two decimals(one pound is 0.45359237 kilograms)\n",
    "#         data['weight'] = round(data.weight * 0.45359237,2)\n",
    "#         return data\n",
    "\n",
    "def transform(data): # convert height from inches to metres, and weight from pounds to kilos\n",
    "    data['height'] = round(data.height * 0.0254,2)\n",
    "    data ['weight'] = round(data.weight * 0.45359237,2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load(targetfile,data_to_load):\n",
    "#     data_to_load.to_csv(targetfile)  \n",
    "\n",
    "def load(targetfile,data_to_load):\n",
    "    data_to_load.to_csv(targetfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log(message):\n",
    "#     timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
    "#     now = datetime.now() # get current timestamp\n",
    "#     timestamp = now.strftime(timestamp_format)\n",
    "#     with open(\"logfile.txt\",\"a\") as f:\n",
    "#         f.write(timestamp + ',' + message + '\\n')\n",
    "\n",
    "def log(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S'\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"Logfile.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ETL Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"ETL Job Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-6b1cf0dea497>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extract phase Started\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mextracted_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extract phase Ended\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mextracted_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-59f35250bb44>\u001b[0m in \u001b[0;36mextract\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Lastly, process all xml files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mxmlFile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"*.xml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mextracted_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextracted_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmlExtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmlFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mextracted_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-ad268bb68c97>\u001b[0m in \u001b[0;36mxmlExtract\u001b[1;34m(xmlFile)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mperson\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"height\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weight\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "log(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "log(\"Extract phase Ended\")\n",
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"Transform phase Started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "log(\"Transform phase Ended\")\n",
    "transformed_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"Load phase Started\")\n",
    "load(targetfile,transformed_data)\n",
    "log(\"Load phase Ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"ETL Job Ended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the example above complete the exercise below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-07-02 21:49:44--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4249 (4.1K) [application/zip]\n",
      "Saving to: 'datasource.zip'\n",
      "\n",
      "     0K ....                                                  100%  900M=0s\n",
      "\n",
      "2021-07-02 21:49:45 (900 MB/s) - 'datasource.zip' saved [4249/4249]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  datasource.zip\n",
      "  inflating: dealership_data/used_car_prices1.csv  \n",
      "  inflating: dealership_data/used_car_prices2.csv  \n",
      "  inflating: dealership_data/used_car_prices3.csv  \n",
      "  inflating: dealership_data/used_car_prices1.json  \n",
      "  inflating: dealership_data/used_car_prices2.json  \n",
      "  inflating: dealership_data/used_car_prices3.json  \n",
      "  inflating: dealership_data/used_car_prices1.xml  \n",
      "  inflating: dealership_data/used_car_prices2.xml  \n",
      "  inflating: dealership_data/used_car_prices3.xml  \n"
     ]
    }
   ],
   "source": [
    "!unzip datasource.zip -d dealership_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `dealership_data` contains CSV, JSON, and XML files for used car data which contain features named `car_model`, `year_of_manufacture`, `price`, and `fuel`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile    = \"dealership_temp.tmp\"               # file used to store all extracted data\n",
    "logfile    = \"dealership_logfile.txt\"            # all event logs will be stored in this file\n",
    "targetfile = \"dealership_transformed_data.csv\"   # file where transformed data is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: CSV Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the CSV extract function below\n",
    "\n",
    "\n",
    "def csvExtract(csvFile):\n",
    "    dataframe = pd.read_csv(csvFile)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "    \n",
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: JSON Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the JSON extract function below\n",
    "\n",
    "def jsonExtract(jsonFile):\n",
    "    dataframe = pd.read_json(jsonFile, lines=True)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "    \n",
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process,lines=True)\n",
    "    return dataframe\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: XML Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the XML extract function below, it is the same as the xml extract function above but the column names need to be renamed.\n",
    "\n",
    "def xmlExtract(xmlFile):\n",
    "    dataframe = pd.dataframe(columns=[\"car_model\", \"year_of_manufacture\", \"price\", \"fuel\"])\n",
    "    tree = ET.parse(xmlFile)\n",
    "    root = tree.getroot()\n",
    "    for vehicle in root:\n",
    "        car_model = vehicle.find(\"car_model\").text\n",
    "        year_of_manufacture = float(vehicle.find(\"year_of_manufacture\").text)\n",
    "        price = float(vehicle.find(\"price\").text)\n",
    "        fuel = float(vehicle.find(\"fuel\").text)\n",
    "        dataframe = dataframe.append({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, ignore_index=True)\n",
    "    return dataframe    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "    \n",
    "def extract_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel'])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        car_model = person.find(\"car_model\").text\n",
    "        year_of_manufacture = int(person.find(\"year_of_manufacture\").text)\n",
    "        price = float(person.find(\"price\").text)\n",
    "        fuel = person.find(\"fuel\").text\n",
    "        dataframe = dataframe.append({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, ignore_index=True)\n",
    "    return dataframe\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Extract Function\n",
    "\n",
    "Call the specific extract functions you created above by replacing the `ADD_FUNCTION_CALL` with the proper function call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvFile in glob.glob(\"dealership_data/*.csv\"):\n",
    "        extracted_data = extracted_data.append(csvExtract(csvFile), ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonFile in glob.glob(\"dealership_data/*.json\"):\n",
    "        extracted_data = extracted_data.append(jsonExtract(jsonFile), ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlFile in glob.glob(\"dealership_data/*.xml\"):\n",
    "        extracted_data = extracted_data.append(xmlExtract(xmlFile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "    \n",
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n",
    "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n",
    "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n",
    "        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Transform\n",
    "\n",
    "Round the `price` columns to 2 decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the transform function below\n",
    "\n",
    "def transform(data):\n",
    "    data['price'] = round(data.price,2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "\n",
    "def transform(data):\n",
    "        data['price'] = round(data.price, 2)\n",
    "        return data\n",
    "\n",
    "```\n",
    "</details>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the load function below\n",
    "\n",
    "def loadData(targetfile,loadFile):\n",
    "    targetfile.to_csv(loadFile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "\n",
    "def load(targetfile,data_to_load):\n",
    "    data_to_load.to_csv(targetfile)  \n",
    "\n",
    "```\n",
    "</details>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Log\n",
    "\n",
    "Make sure to change the name of the logfile to the one specified in the set paths section. Change the timestamp order to Hour-Minute-Second-Monthname-Day-Year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the log function below\n",
    "\n",
    "def log(message):\n",
    "    timestamp_format = '%H:%M:%S-%h-%d-%Y'\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"dealership_logfile.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "\n",
    "def log(message):\n",
    "    timestamp_format = '%H:%M:%S-%h-%d-%Y' #Hour-Minute-Second-MonthName-Day-Year\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"dealership_logfile.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n') \n",
    "\n",
    "```\n",
    "</details>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ETL Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: ETL Process\n",
    "\n",
    "Run all functions to extract, transform, and load the data. Make sure to log all events using the `log` function. Place your code under each comment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-14916e7c2399>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Call the Extract function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mextracted_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Log that you have completed the Extract step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-59f35250bb44>\u001b[0m in \u001b[0;36mextract\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Lastly, process all xml files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mxmlFile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"*.xml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mextracted_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextracted_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmlExtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmlFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mextracted_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-6811585737fa>\u001b[0m in \u001b[0;36mxmlExtract\u001b[1;34m(xmlFile)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mxmlExtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmlFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"height\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"weight\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmlFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rosss\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'dataframe'"
     ]
    }
   ],
   "source": [
    "# Log that you have started the ETL process\n",
    "log(\"ETL Process Started\")\n",
    "\n",
    "# Log that you have started the Extract step\n",
    "\n",
    "log(\"Extract step started\")\n",
    "\n",
    "# Call the Extract function\n",
    "\n",
    "extracted_data = extract()\n",
    "\n",
    "# Log that you have completed the Extract step\n",
    "\n",
    "log(\"Extract step complete\")\n",
    "\n",
    "# Log that you have started the Transform step\n",
    "\n",
    "log(\"Transform step started\")\n",
    "\n",
    "# Call the Transform function\n",
    "\n",
    "transformeddata = transform(extracted_data)\n",
    "\n",
    "# Log that you have completed the Transform step\n",
    "\n",
    "log(\"Transform step complete\")\n",
    "\n",
    "# Log that you have started the Load step\n",
    "\n",
    "log(\"Load step started\")\n",
    "\n",
    "# Call the Load function\n",
    "\n",
    "loadData(targetfile,loadFile)\n",
    "\n",
    "# Log that you have completed the Load step\n",
    "\n",
    "log(\"Load step complete\")\n",
    "\n",
    "# Log that you have completed the ETL process\n",
    "\n",
    "log(\"ETL process complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "    \n",
    "```\n",
    "\n",
    "log(\"ETL Job Started\")\n",
    "\n",
    "log(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "log(\"Extract phase Ended\")\n",
    "\n",
    "log(\"Transform phase Started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "log(\"Transform phase Ended\")\n",
    "\n",
    "log(\"Load phase Started\")\n",
    "load(targetfile,transformed_data)\n",
    "log(\"Load phase Ended\")\n",
    "\n",
    "log(\"ETL Job Ended\")\n",
    "\n",
    "```\n",
    "</details>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n",
    "\n",
    "Joseph Santarcangelo\n",
    "\n",
    "Azim Hirjani\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- |\n",
    "| 2020-11-25        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright © 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork-23455645&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork-23455645&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork-23455645&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork-23455645&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
